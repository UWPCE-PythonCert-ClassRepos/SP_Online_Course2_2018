{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the sources\n",
      "['abc-news-au', 'al-jazeera-english', 'ars-technica', 'associated-press', 'bbc-news', 'bbc-sport', 'bloomberg', 'breitbart-news', 'business-insider', 'business-insider-uk', 'buzzfeed', 'cnbc', 'cnn', 'daily-mail', 'engadget', 'entertainment-weekly', 'espn', 'espn-cric-info', 'financial-times', 'football-italia', 'fortune', 'four-four-two', 'fox-sports', 'google-news', 'hacker-news', 'ign', 'independent', 'mashable', 'metro', 'mirror', 'mtv-news', 'mtv-news-uk', 'national-geographic', 'new-scientist', 'newsweek', 'new-york-magazine', 'nfl-news', 'polygon', 'recode', 'reddit-r-all', 'reuters', 'talksport', 'techcrunch', 'techradar', 'the-economist', 'the-hindu', 'the-huffington-post', 'the-lad-bible', 'the-new-york-times', 'the-next-web', 'the-sport-bible', 'the-telegraph', 'the-times-of-india', 'the-verge', 'the-wall-street-journal', 'the-washington-post', 'time', 'usa-today']\n",
      "requesting:Thread Thread-4 started abc-news-au\n",
      "\n",
      "requesting: Thread Thread-5 started\n",
      "requesting:abc-news-au \n",
      "Thread Thread-6 started\n",
      "abc-news-au\n",
      "requesting:Thread Thread-7 started\n",
      " abc-news-au\n",
      "requesting: al-jazeera-english\n",
      "requesting: al-jazeera-english\n",
      "requesting: al-jazeera-english\n",
      "requesting: al-jazeera-english\n",
      "requesting: ars-technica\n",
      "requesting: ars-technica\n",
      "requesting: ars-technica\n",
      "requesting: ars-technica\n",
      "requesting: associated-press\n",
      "requesting: associated-press\n",
      "requesting: requesting:associated-press \n",
      "associated-press\n",
      "requesting: bbc-news\n",
      "requesting: requesting: bbc-news\n",
      "bbc-news\n",
      "requesting: bbc-news\n",
      "requesting: bbc-sport\n",
      "requesting: bbc-sport\n",
      "requesting: bbc-sport\n",
      "requesting: bbc-sport\n",
      "requesting: bloomberg\n",
      "requesting: bloomberg\n",
      "requesting: bloomberg\n",
      "requesting: bloomberg\n",
      "requesting: breitbart-news\n",
      "requesting: breitbart-news\n",
      "requesting:requesting: breitbart-news\n",
      " breitbart-news\n",
      "requesting: business-insider\n",
      "requesting: business-insider\n",
      "requesting: business-insider\n",
      "requesting: business-insider\n",
      "requesting: business-insider-uk\n",
      "requesting: business-insider-uk\n",
      "requesting: business-insider-uk\n",
      "requesting: business-insider-uk\n",
      "requesting: buzzfeed\n",
      "requesting: buzzfeed\n",
      "requesting: buzzfeed\n",
      "requesting: buzzfeed\n",
      "requesting: cnbc\n",
      "requesting: cnbc\n",
      "requesting: cnbc\n",
      "requesting: cnbc\n",
      "requesting: cnn\n",
      "requesting: cnn\n",
      "requesting: cnn\n",
      "requesting: cnn\n",
      "requesting: daily-mail\n",
      "requesting: daily-mail\n",
      "requesting: daily-mail\n",
      "requesting: daily-mail\n",
      "requesting: requesting: engadget\n",
      "engadget\n",
      "requesting: engadget\n",
      "requesting: engadget\n",
      "requesting:requesting:  entertainment-weekly\n",
      "entertainment-weekly\n",
      "requesting: requesting:entertainment-weekly entertainment-weekly\n",
      "\n",
      "requesting: espn\n",
      "requesting: espn\n",
      "requesting: espn\n",
      "requesting: espn\n",
      "requesting: espn-cric-info\n",
      "requesting: espn-cric-info\n",
      "requesting: espn-cric-info\n",
      "requesting: espn-cric-info\n",
      "requesting: financial-times\n",
      "requesting: financial-times\n",
      "requesting: financial-times\n",
      "requesting: financial-times\n",
      "requesting: football-italia\n",
      "requesting: football-italia\n",
      "requesting: football-italia\n",
      "requesting: football-italia\n",
      "requesting: fortune\n",
      "requesting: fortune\n",
      "requesting: fortune\n",
      "requesting: fortune\n",
      "requesting:requesting:  four-four-two\n",
      "four-four-two\n",
      "requesting:requesting: four-four-two\n",
      " four-four-two\n",
      "requesting: requesting: fox-sports\n",
      "fox-sports\n",
      "requesting: fox-sports\n",
      "requesting: fox-sports\n",
      "requesting: google-news\n",
      "requesting: google-news\n",
      "requesting: google-news\n",
      "requesting: google-news\n",
      "requesting: hacker-news\n",
      "requesting: hacker-news\n",
      "requesting: hacker-news\n",
      "requesting: hacker-news\n",
      "requesting: ign\n",
      "requesting: ign\n",
      "requesting:requesting: ign\n",
      " ign\n",
      "requesting: independent\n",
      "requesting: independent\n",
      "requesting: independent\n",
      "requesting: independent\n",
      "requesting: mashable\n",
      "requesting: mashable\n",
      "requesting: mashable\n",
      "requesting: mashable\n",
      "requesting:requesting: metro\n",
      " metro\n",
      "requesting: metro\n",
      "requesting: metro\n",
      "requesting:requesting: mirror\n",
      " mirror\n",
      "requesting:requesting: mirror \n",
      "mirror\n",
      "requesting: mtv-news\n",
      "requesting: mtv-news\n",
      "requesting: mtv-newsrequesting: mtv-news\n",
      "\n",
      "requesting: mtv-news-uk\n",
      "requesting: mtv-news-uk\n",
      "requesting: mtv-news-uk\n",
      "requesting: mtv-news-uk\n",
      "requesting: national-geographic\n",
      "requesting: national-geographic\n",
      "requesting:requesting: national-geographic\n",
      " national-geographic\n",
      "requesting: new-scientist\n",
      "requesting: new-scientist\n",
      "requesting: new-scientist\n",
      "requesting: new-scientist\n",
      "requesting: newsweek\n",
      "requesting: newsweek\n",
      "requesting: newsweek\n",
      "requesting: newsweek\n",
      "requesting: new-york-magazine\n",
      "requesting: new-york-magazine\n",
      "requesting: new-york-magazine\n",
      "requesting: new-york-magazine\n",
      "requesting: nfl-news\n",
      "requesting: nfl-news\n",
      "requesting: nfl-news\n",
      "requesting: nfl-news\n",
      "requesting:requesting: polygon\n",
      " polygon\n",
      "requesting: polygon\n",
      "requesting: polygon\n",
      "requesting: recode\n",
      "requesting: recode\n",
      "requesting: recode\n",
      "requesting: recode\n",
      "requesting: reddit-r-all\n",
      "requesting: reddit-r-all\n",
      "requesting: reddit-r-all\n",
      "requesting: reddit-r-all\n",
      "requesting: reuters\n",
      "requesting: reuters\n",
      "requesting: reuters\n",
      "requesting: reuters\n",
      "requesting: talksport\n",
      "requesting: talksport\n",
      "requesting: talksport\n",
      "requesting: talksport\n",
      "requesting: techcrunch\n",
      "requesting: techcrunch\n",
      "requesting: techcrunch\n",
      "requesting: techcrunch\n",
      "requesting: techradar\n",
      "requesting: techradar\n",
      "requesting: techradar\n",
      "requesting: techradar\n",
      "requesting: the-economist\n",
      "requesting: the-economist\n",
      "requesting: the-economist\n",
      "requesting: the-economist\n",
      "requesting:requesting:  the-hindu\n",
      "requesting:the-hindu the-hindu\n",
      "\n",
      "requesting: the-hindu\n",
      "requesting:requesting:  the-huffington-post\n",
      "the-huffington-post\n",
      "requesting:requesting: the-huffington-post\n",
      " the-huffington-post\n",
      "requesting: the-lad-bible\n",
      "requesting: the-lad-bible\n",
      "requesting: the-lad-bible\n",
      "requesting: the-lad-bible\n",
      "requesting: the-new-york-times\n",
      "requesting: requesting: the-new-york-times\n",
      "the-new-york-timesrequesting: the-new-york-times\n",
      "\n",
      "requesting: the-next-web\n",
      "requesting: the-next-web\n",
      "requesting:requesting: the-next-web\n",
      " the-next-web\n",
      "requesting: requesting: the-sport-bible\n",
      "the-sport-bible\n",
      "requesting: the-sport-bible\n",
      "requesting: the-sport-bible\n",
      "requesting: the-telegraph\n",
      "requesting: the-telegraph\n",
      "requesting: requesting: the-telegraph\n",
      "the-telegraph\n",
      "requesting: the-times-of-indiarequesting: the-times-of-india\n",
      "\n",
      "requesting: the-times-of-india\n",
      "requesting: the-times-of-india\n",
      "requesting: the-verge\n",
      "requesting: the-verge\n",
      "requesting: the-verge\n",
      "requesting: the-verge\n",
      "requesting: the-wall-street-journal\n",
      "requesting: the-wall-street-journal\n",
      "requesting: the-wall-street-journal\n",
      "requesting: the-wall-street-journal\n",
      "requesting: the-washington-post\n",
      "requesting: the-washington-post\n",
      "requesting:requesting: the-washington-post\n",
      " the-washington-post\n",
      "requesting: time\n",
      "requesting: time\n",
      "requesting: time\n",
      "requesting: time\n",
      "requesting:requesting:  usa-today\n",
      "usa-todayrequesting:\n",
      " usa-today\n",
      "requesting: usa-today\n",
      "war found 172 times in 2124 articles\n",
      "Process took 24 seconds\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Threaded Downloader\n",
    "\"\"\"\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    NEWS_API_KEY = \"1644ea0ae3684a9aa16b0cffed5bbdcc\"\n",
    "\n",
    "    base_url = 'https://newsapi.org/v1/'\n",
    "    WORD = \"war\"\n",
    "    TITLES = []    \n",
    "    thread_count = 4\n",
    "    art_count = 0\n",
    "    word_count = 0\n",
    "    \n",
    "    def get_sources():\n",
    "        url = base_url + \"sources\"\n",
    "        params = {\"language\":\"en\"}\n",
    "        resp = requests.get(url, params=params)\n",
    "        data = resp.json()\n",
    "        sources = [src['id'].strip() for src in data['sources']]\n",
    "        print(\"all the sources\")\n",
    "        print(sources)\n",
    "        return sources\n",
    "\n",
    "    def get_articles(sources):\n",
    "        for source in sources:\n",
    "            url = base_url + \"articles\"\n",
    "            params = {\"source\": source,\n",
    "                      \"apiKey\": NEWS_API_KEY,\n",
    "                      \"sortBy\": \"top\",\n",
    "                      }\n",
    "            print(\"requesting:\", source)\n",
    "            resp = requests.get(url, params=params)\n",
    "            if resp.status_code != 200:  # aiohttpp has \"status\"\n",
    "                print(\"something went wrong with {}\".format(source))\n",
    "                print(resp)\n",
    "                print(resp.text)\n",
    "                return []\n",
    "            data = resp.json()\n",
    "            for art in data['articles']:\n",
    "                TITLES.append(str(art['title']) + str(art['description']))\n",
    "\n",
    "    def articles_threading(sources, thread_count=1):\n",
    "        results = queue.Queue()\n",
    "        sources = sources\n",
    "        threads = []\n",
    "\n",
    "        def worker(*args):\n",
    "            results.put(get_articles(*args))\n",
    "\n",
    "        for i in range(thread_count):\n",
    "            thread = threading.Thread(target=worker, args=(sources,))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            print(\"Thread %s started\" % thread.name)\n",
    "\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    def count_word(word, titles):\n",
    "        word = word.lower()\n",
    "        count = 0\n",
    "        for title in titles:\n",
    "            if word in title.lower():\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    start = time.time()\n",
    "    sources = get_sources()\n",
    "    articles_threading(sources, thread_count)\n",
    "    count_word(WORD, TITLES)\n",
    "    art_count += len(TITLES)\n",
    "    word_count += count_word(WORD, TITLES)\n",
    "\n",
    "    print(WORD, \"found {} times in {} articles\".format(word_count, art_count))\n",
    "    print(\"Process took {:.0f} seconds\".format(time.time() - start))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
